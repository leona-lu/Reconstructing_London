---
title: "St Paul's Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# This file analyzes texts containing St Paul's cathedral and performs sentiment analysis and hapax richness. 


```{r import-packages}
library(tidyverse)
library(dplyr)
library(tidytext)
library(stringr)
library(ggplot2)
library(scales)
library(tidyverse)
library(XML)
library(quanteda.textstats)
library(quanteda)

```

```{r import-data}
data <- read_csv("D://csv/2700_text.csv")
data$title <- tolower(data$title)
data$text <- tolower(data$text)
```



# Observation Test

```{r sentiment}
# extracts sentiment tokens from texts and uses bing lexicon to compute the overall sentiment for each text
extracted <- read_csv("C:/Users/erika/PycharmProjects/Converting/combined_text.csv")

extracted$title <- tolower(extracted$title)
extracted$text <- tolower(extracted$text)

extracted <- extracted %>%
  arrange(title) %>%
  filter(duplicated(title) == FALSE) %>%
  filter(duplicated(text) == FALSE) %>%
  filter(date >= 1660)

newdata <- subset(data, title %in% extracted$title)

newdata <- newdata %>%
  arrange(title) %>%
  filter(duplicated(title) == FALSE) %>%
  filter(date >= 1660)
  
tokens <- extracted %>%
  group_by(date) %>%
  ungroup() %>%
  unnest_tokens(word, text)

#get_sentiments("bing")

sample_sentiment <- tokens %>%
  inner_join(get_sentiments("bing")) %>%
  count(date, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = (positive) / (positive + negative))
sample_sentiment

```

# Visualizations
```{r sentiment-graph}
# Creates a line graph showing change in sentiment through the 17th century

df <- extracted %>%
  left_join(sample_sentiment) %>%
  select(title, author, date, text, negative, positive, sentiment) %>%
  mutate(sapply(strsplit(text, " "), length))
df


plot <- ggplot(df, aes(x=date, y=sentiment)) +
  geom_line(color = "firebrick2") +
  geom_smooth(method = "lm", se = FALSE, lwd = 0.1, color = "firebrick2") +
  ylim(0.4, 0.9) + 
  scale_x_continuous(breaks= pretty_breaks()) + 
  theme_minimal() + 
  labs(title = "Sentiment Analysis on St. Paul\'s Cathedral", subtitle = "using BING lexicon, from 1660-1700", x = "Date", y = "Sentiment")
plot


```

# Hapax Richness

```{r hapax}
# Computes the hapax richness of each text
Hapax_richness <- function(dataframe){
  result <- data.frame(matrix(ncol = 2, nrow = nrow(dataframe)))
  x <- c("title", "Hapax")
  colnames(result) <- x
  for (i in 1:nrow(dataframe)){
    dfm <- dfm(tokens(dataframe$text[[i]]))
    result$title <- dataframe$title
    result$Hapax[[i]] <- rowSums(dfm == 1) / ntoken(dfm)
    }
  return(result)
  }

# Create result
Hapax_Result <- Hapax_richness(newdata)
Hapax_Result
```

# Lexical Richness by years

```{r hapax-graph}
# Creates graph showing change in hapax richness through the 17th century

hr_by_year <- Hapax_Result %>%
  left_join(newdata) 

hapax_by_year <- hr_by_year %>%
  group_by(date) %>%
  summarise(count = n(), mean_Hapax = mean(Hapax, na.rm = TRUE))

hapaxplot <- ggplot(hapax_by_year, aes(x= date, y=mean_Hapax)) +
  geom_line(color = "cyan4") +
  geom_smooth(method = "lm", se = FALSE, lwd = 0.1, color = "cyan4") +
  scale_x_continuous(breaks= pretty_breaks()) +
  ylim(0, 0.15) +
  theme_minimal()+ 
  labs(title = "Hapax Richness of St Paul\'s Texts", subtitle = "from 1660-1700", x = "Date", y = "Mean Hapax")
hapaxplot

```

```{r edits}
# Final edits made to the plots
plot + 
  labs(title = "Sentiment Analysis on St. Paul\'s Cathedral", subtitle = "using BING lexicon, from 1600-1700")
hapaxplot + 
  labs(title = "Hapax Richness of St Paul\'s Texts", subtitle = "from 1600-1700")

```
