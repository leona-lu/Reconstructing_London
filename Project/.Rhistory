# Load Cleaned_CSV
P1 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P1.csv")
P2 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P2.csv")
P3 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P3.csv")
P4 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P4.csv")
P5 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P5.csv")
P6 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P6.csv")
P7 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P7.csv")
P8 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P8.csv")
P9 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P9.csv")
P10 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P10.csv")
P11 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P11.csv")
P12 <- read.csv("/Users/yuchenlu/Desktop/Reconstructing_London/Project/Cleaned_CSV/Cleaned_Data_P12.csv")
## Merge CSV
total <- rbind(P1, P2)
total <- rbind(total, P3)
total <- rbind(total, P4)
total <- rbind(total, P5)
total <- rbind(total, P6)
total <- rbind(total, P7)
total <- rbind(total, P8)
total <- rbind(total, P9)
total <- rbind(total, P10)
total <- rbind(total, P11)
total <- rbind(total, P12)
write.csv(total,'total.csv')
## Basic EDA
P1 %>%
count(Date)
# Load Library
library(XML)
library(tidyverse)
library(textmineR)
# Basic EDA
P1 %>%
count(Date)
# Basic EDA
P1 %>%
count(Date) %>%
as_tibble()
# Basic EDA
data <- P1 %>%
count(Date) %>%
as_tibble()
View(data)
# Basic EDA
data <- P1 %>%
count(Date) %>%
as_tibble() %>%
ggplot(aes(x=Date,y=n)) +
geom_bar()
# Basic EDA
P1 %>%
count(Date) %>%
as_tibble() %>%
ggplot(aes(x=Date,y=n)) +
geom_bar()
# Basic EDA
P1 %>%
count(Date) %>%
ggplot(aes(x=Date,y=n)) +
geom_bar()
# Basic EDA
P1 %>%
count(Date) %>%
as_tibble() %>%
ggplot(aes(x=Date,y=n)) +
geom_bar()
# Basic EDA
P1 %>%
count(Date) %>%
as_tibble() %>%
ggplot(aes(x=Date)) +
geom_bar()
# Basic EDA
P1 %>%
count(Date) %>%
as_tibble()
# Basic EDA
Date_Count <- P1 %>%
count(Date) %>%
as_tibble()
View(data)
View(Date_Count)
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line()
Date_Count <- P1 %>%
count(Date) %>%
as_tibble()
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line()
View(total)
Date_Count <- total %>%
count(Date) %>%
as_tibble()
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line() +
labs(title = "",
subtitle = "Plot of length by dose",
caption = "Data source: ToothGrowth",
x = "Dose (mg)", y = "Teeth length")
View(Date_Count)
Date_Count <- total %>%
count(Date) %>%
as_tibble()
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line() +
labs(title = "",
subtitle = "Texts printed from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
Date_Count <- total %>%
count(Date) %>%
as_tibble()
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line() +
labs(title = "",
subtitle = "Texts printed from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
knitr::opts_chunk$set(echo = TRUE)
# Input: Document-featured matrix; Output: lexical richness
Lexical_richness <- function(dataframe){
result <- textstat_lexdiv(dfm(tokens(dataframe$texts[[1]])),
c("all"))
for (i in 2:nrow(dataframe)){
dfm <- dfm(tokens(dataframe$texts[[i]]))
result <- rbind(result, textstat_lexdiv(dfm, c("all")))
}
result$TCP <- dataframe$TCP
return(result)
}
# Create result
# TTR_Result <- Lexical_richness(test_df)
TTR_Result <- Lexical_richness(total)
library(tidyverse)
library(XML)
library(quanteda.textstats)
library(quanteda)
library(quanteda.textplots)
TTR_Result <- Lexical_richness(total)
Hapax_richness <- function(dataframe){
result <- data.frame(matrix(ncol = 2, nrow = nrow(dataframe)))
x <- c("TCP", "Hapax")
colnames(result) <- x
for (i in 1:nrow(dataframe)){
dfm <- dfm(tokens(dataframe$texts[[i]]))
result$TCP <- dataframe$TCP
result$Hapax[[i]] <- rowSums(dfm == 1) / ntoken(dfm)
}
return(result)
}
# Create result
Hapax_Result <- Hapax_richness(total)
total$token <- ntoken(as.character(total$texts))
total$type  <- ntype(as.character(total$texts))
write.csv(total,'total.csv')
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point()
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type")
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="auto", se=TRUE, fullrange=FALSE, level=0.95)
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="lm", se=TRUE, fullrange=FALSE, level=0.95)
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95)
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth()
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="lm")
# method="lm", se=FALSE, fullrange=FALSE, level=0.95
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="lm", linetype="dashed",
color="darkred", fill="blue")
# method="lm", se=FALSE, fullrange=FALSE, level=0.95
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(method="lm", linetype="dashed",
color="darkred", fill="grey")
# method="lm", se=FALSE, fullrange=FALSE, level=0.95
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
# method="lm", se=FALSE, fullrange=FALSE, level=0.95
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x =log(token), y = log(type))) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
# method="lm", se=FALSE, fullrange=FALSE, level=0.95
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
total %>%
ggplot(aes(x =log(token), y = log(type))) +
geom_point() +
labs(title = "",
subtitle = "Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
# total$token <- ntoken(as.character(total$texts))
# total$type  <- ntype(as.character(total$texts))
# TTR display non-linear Relationship
total %>%
ggplot(aes(x = token, y = type)) +
geom_point() +
labs(title = "",
subtitle = "Type-Token ratio ratio has non-linear relationship",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
# Using Log to Normalize the TTR Ratio (linear asusmption)
total %>%
ggplot(aes(x =log(token), y = log(type))) +
geom_point() +
labs(title = "",
subtitle = "Log Normalized Type-Token Ratio Ratio",
caption = "Data source: EEBO-TCP",
x = "Token", y = "Type") +
geom_smooth(linetype="dashed",
color="darkred", fill="grey")
# TTR by Year
total$adjusted.TTR <- log(total$type)/log(total$token)
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
ggplot(total,aes(x=Date,y=adjusted.TTR)) +
geom_point() +
labs(title = "",
subtitle = "Texts printed from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR))
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_point() +
labs(title = "",
subtitle = "Texts printed from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_line() +
labs(title = "",
subtitle = "Texts printed from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
View(Date_Count)
Date_Count <- total %>%
count(Date) %>%
as_tibble()
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line() +
labs(title = "Texts printed from 1600 to 1700",
subtitle = "Number of text peaked at 1642 and 1660",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_line() +
labs(title = "Average Lexical Richness from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Average Lexical Richness")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_line() +
labs(title = "Average Log-adjusted Lexical Richness from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Average Lexical Richness")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_line() +
labs(title = "Average Log-adjusted Lexical Richness from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Average Lexical Richness") +
ggplot(Date_Count,aes(x=Date,y=n)) +
geom_line() +
labs(title = "Texts printed from 1600 to 1700",
subtitle = "Number of text peaked at 1642 and 1660",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Number of Texts")
# TTR by Year
# total$adjusted.TTR <- log(total$type)/log(total$token)
total %>%
group_by(Date) %>%
summarise(
average.TTR = mean(adjusted.TTR)) %>%
ggplot(aes(x=Date,y=average.TTR)) +
geom_line() +
labs(title = "Average Log-adjusted Lexical Richness from 1600 to 1700",
caption = "Data source: EEBO-TCP",
x = "Year", y = "Average Lexical Richness")
Case <- filter_Paul(P1)
filter_Paul <- function(df){
df <- df %>%
filter(grepl('st paul|st.paul|paul|st faith|st.faith',texts)) %>%
filter(grepl('cathedral|cathederall|cathedral|churchyard',texts))
return(df)
}
filter_Mary <- function(df){
df <- df %>%
filter(grepl('st mary|st.mary|mary',texts)) %>%
filter(grepl('cathedral|cathederall|cathedral|churchyard|aldermary',texts))
return(df)
}
Case <- filter_Paul(P1)
View(Case)
